head(turbofan_df)
table(turbofan_df$status)
# Calculate the squared correlation matrix and convert to long format
squared_corr <- cor(turbofan_df)^2
melted_corr <- melt(squared_corr)
# Filter for stronger correlations to reduce clutter
threshold <- 0.5 # Example threshold, adjust as needed
melted_corr_filtered <- subset(melted_corr, value >= threshold & Var1 != Var2)
# Create the heatmap
ggplot(melted_corr_filtered, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
axis.title = element_blank()) +
labs(fill = "Squared\nCorrelation") +
geom_text(aes(label = sprintf("%.2f", value)), size = 3)
# Selected numeric and category columns
selected_columns <- c("sensor_measurement_04", "sensor_measurement_11", "sensor_measurement_14", "operational_setting_3", "sensor_measurement_16", "status", "cycle")
# Assuming 'turbofan_df' is a dataframe and columns are appropriately formatted
cleaned_data <- turbofan_df[selected_columns]
# Calculate the squared correlation matrix and convert to long format
squared_corr <- cor(cleaned_data)^2
melted_corr <- melt(squared_corr)
# Filter for stronger correlations to reduce clutter
threshold <- 0.5 # Example threshold, adjust as needed
melted_corr_filtered <- subset(melted_corr, value >= threshold & Var1 != Var2)
# Create the heatmap
ggplot(melted_corr_filtered, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
axis.title = element_blank()) +
labs(fill = "Squared\nCorrelation") +
geom_text(aes(label = sprintf("%.2f", value)), size = 3)
unique_counts <- sapply(turbofan_df, function(x) length(unique(x)))
cat("Unique values count per column:\n")
for(col in names(unique_counts)) {
cat(col, ":", unique_counts[col], "\n")
}
# Change specified columns to category (factor)
turbofan_df <- turbofan_df %>%
mutate(across(c(operational_setting_3, sensor_measurement_16, sensor_measurement_19), as.factor))
# View information about the dataframe to confirm the changes
glimpse(turbofan_df)
library(survival)
library(dplyr)
library(glmnet)
attach(turbofan_df)
fit.surv <- survfit(Surv(max_cycle, status) ~ 1)
plot(fit.surv, xlab = "Cycles", ylab = "Estimated Probability for Survival")
print(fit.surv)
### Operational Setting 3
fit.op <- survfit(Surv(max_cycle, status) ~ operational_setting_3)
plot(fit.op, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c (2 ,4))
legend_labels <- levels(operational_setting_1)
legend("topright", levels(operational_setting_3), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ operational_setting_3)
logrank.test
coxph(Surv(max_cycle, status) ~ operational_setting_3)
fit.sm <- survfit(Surv(max_cycle, status) ~ sensor_measurement_16)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c(2,4))
legend("topright", levels(sensor_measurement_16), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ sensor_measurement_16)
logrank.test
fit.sm <- survfit(Surv(max_cycle, status) ~ sensor_measurement_19)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c(2,4))
legend("topright", levels(sensor_measurement_19), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ sensor_measurement_19)
logrank.test
coxph(Surv(max_cycle, status) ~ sensor_measurement_19)
model <- coxph(Surv(max_cycle, status) ~ ., data = turbofan_df)
summary(model)
show_fit=glmnet(turbofan_df,Surv(max_cycle, status),standardize=TRUE,
lambda=seq(0,0.5,.01),alpha=1,family = "cox", maxit = 5000000)
print(show_fit)
plot(show_fit)
p <- ncol(turbofan_df) - 2
data <- as.matrix(turbofan_df[, 3:p])
surv_model <- cv.glmnet(data,Surv(max_cycle,status), family = "cox",
type.measure = "deviance",alpha=1,nfolds = 10)
plot(show_fit,label=TRUE)
plot(show_fit,xvar = "lambda",label=TRUE)
print(surv_model)
lambda_opt <- surv_model$lambda.1se
fit <- glmnet(data,Surv(max_cycle,status), family = "cox",
type.measure = "deviance",alpha=1,lambda = lambda_opt)
coef(fit)
plot(fit)
predictions <- predict(fit, newx = data, type = "response")
c_index <- Cindex(predictions,Surv(max_cycle, status))
print(c_index)
surv_model_C = cv.glmnet(data,Surv(max_cycle,status), family = "cox",
type.measure = "C", alpha=1,nfolds = 10)
plot(surv_model_C)
print(surv_model_C)
############### Basic GLMNET
p <- ncol(turbofan_df) - 2
data <- as.matrix(turbofan_df[, 3:p])
data <- as.matrix(turbofan_df[, 3:p])
data <- as.matrix(turbofan_df[, 3:p])
show_fit=glmnet(data,Surv(max_cycle, status),standardize=TRUE,
lambda=seq(0,0.25,.001),alpha=1,family = "cox")
print(show_fit)
plot(show_fit,label=TRUE)
plot(show_fit,xvar = "lambda",label=TRUE)
################## Partial Devience
surv_model <- cv.glmnet(data,Surv(y, failed), family = "cox",
type.measure = "deviance",alpha=1,nfolds = 10)
################## Partial Devience
surv_model <- cv.glmnet(data,Surv(max_cycle, status), family = "cox",
type.measure = "deviance",alpha=1,nfolds = 10)
plot(surv_model)
print(surv_model)
lambda_opt <- surv_model$lambda.1se
# Fit the model using the optimal lambda value
fit <- glmnet(xmatrix,Surv(y, failed), family = "cox",
type.measure = "deviance",alpha=1,lambda = lambda_opt)
# Fit the model using the optimal lambda value
fit <- glmnet(data,Surv(max_cycle, status), family = "cox",
type.measure = "deviance",alpha=1,lambda = lambda_opt)
coef(fit)
predictions <- predict(fit, newx = xmatrix[,1:p], type = "response")
predictions <- predict(fit, newx = data[,3:p], type = "response")
predictions <- predict(fit, newx = data, type = "response")
View(turbofan_df)
c_index <- Cindex(predictions,Surv(max_cycle, status))
c_index
################## Cindex
surv_model_C = cv.glmnet(data,Surv(max_cycle, status),
family = "cox", type.measure = "C",
alpha=1,nfolds = 10)
plot(surv_model_C)
print(surv_model_C)
lambda_opt <- surv_model_C$lambda.1se
# Fit the model using the optimal lambda value
fit_C <- glmnet(data,Surv(max_cycle, status),
family = "cox",
type.measure = "C",alpha=1,lambda = lambda_opt)
coef(fit_C)
# Make predictions
predictions <- predict(fit_C, newx = xmatrix[,1:p], type = "response")
# Make predictions
predictions <- predict(fit_C, newx = data, type = "response")
# Evaluate the model performance using concordance index (c-index)
c_index <- Cindex(predictions,Surv(y, failed))
# Evaluate the model performance using concordance index (c-index)
c_index <- Cindex(predictions,Surv(max_cycle, status))
c_index
library(readr)
library(dplyr)
library(ggplot2)
library(reshape2)
# Define column names
column1 <- c("machine_name", "cycle", "operational_setting_1", "operational_setting_2", "operational_setting_3")
column2 <- paste0("sensor_measurement_", sprintf("%02d", 1:21))
columns <- c(column1, column2)
# Read Data
turbofan_df <- read_delim("data/train_FD002.txt",
delim = " ", col_names = columns, show_col_types = FALSE, trim_ws = TRUE)
# Dropping Empty Columns
turbofan_df <- turbofan_df %>%
select(-X27, -X28)
head(turbofan_df)
turbofan_df <- turbofan_df %>%
group_by(machine_name) %>%
mutate(max_cycle = max(cycle)) %>%
filter(cycle == max_cycle) %>%
ungroup()
head(turbofan_df)
# Create the lollipop plot
ggplot(turbofan_df, aes(x = machine_name, y = cycle)) +
geom_segment(aes(x = machine_name, xend = machine_name, y = 1, yend = cycle), color = 'skyblue') +
geom_point(color = 'blue', size = 1.5) +
geom_point(aes(y = 1), color = 'red', size = 1.5) +
coord_flip() +
labs(title = "Max. Cycle", x = "Machine ID", y = "Cycle") +
theme_minimal()
# Create status column
turbofan_df <- turbofan_df %>%
mutate(status = ifelse(cycle > 200, FALSE, TRUE))
head(turbofan_df)
table(turbofan_df$status)
# Calculate the squared correlation matrix and convert to long format
squared_corr <- cor(turbofan_df)^2
melted_corr <- melt(squared_corr)
# Filter for stronger correlations to reduce clutter
threshold <- 0.5 # Example threshold, adjust as needed
melted_corr_filtered <- subset(melted_corr, value >= threshold & Var1 != Var2)
# Create the heatmap
ggplot(melted_corr_filtered, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
axis.title = element_blank()) +
labs(fill = "Squared\nCorrelation") +
geom_text(aes(label = sprintf("%.2f", value)), size = 3)
# Selected numeric and category columns
selected_columns <- c("sensor_measurement_04", "sensor_measurement_11", "sensor_measurement_14", "operational_setting_3", "sensor_measurement_16", "status", "cycle")
# Assuming 'turbofan_df' is a dataframe and columns are appropriately formatted
cleaned_data <- turbofan_df[selected_columns]
# Calculate the squared correlation matrix and convert to long format
squared_corr <- cor(cleaned_data)^2
melted_corr <- melt(squared_corr)
# Filter for stronger correlations to reduce clutter
threshold <- 0.5 # Example threshold, adjust as needed
melted_corr_filtered <- subset(melted_corr, value >= threshold & Var1 != Var2)
# Create the heatmap
ggplot(melted_corr_filtered, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
axis.title = element_blank()) +
labs(fill = "Squared\nCorrelation") +
geom_text(aes(label = sprintf("%.2f", value)), size = 3)
unique_counts <- sapply(turbofan_df, function(x) length(unique(x)))
cat("Unique values count per column:\n")
for(col in names(unique_counts)) {
cat(col, ":", unique_counts[col], "\n")
}
# Change specified columns to category (factor)
turbofan_df <- turbofan_df %>%
mutate(across(c(operational_setting_3, sensor_measurement_16, sensor_measurement_19), as.factor))
# View information about the dataframe to confirm the changes
glimpse(turbofan_df)
library(survival)
library(dplyr)
library(glmnet)
attach(turbofan_df)
fit.surv <- survfit(Surv(max_cycle, status) ~ 1)
plot(fit.surv, xlab = "Cycles", ylab = "Estimated Probability for Survival")
summary(fit.surv, times =150)
print(fit.surv)
### Operational Setting 3
fit.op <- survfit(Surv(max_cycle, status) ~ operational_setting_3)
plot(fit.op, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c (2 ,4))
legend_labels <- levels(operational_setting_1)
legend("topright", levels(operational_setting_3), col = c(2,4), lty = 1)
jpeg(file="KM_plot.jpeg")
jpeg(file="KM_plot.jpeg")
plot(fit.surv, xlab = "Cycles", ylab = "Estimated Probability for Survival")
dev.off()
summary(fit.surv, times =150)
print(fit.surv)
### Operational Setting 3
fit.op <- survfit(Surv(max_cycle, status) ~ operational_setting_3)
plot(fit.op, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c (2 ,4))
legend_labels <- levels(operational_setting_1)
legend("topright", levels(operational_setting_3), col = c(2,4), lty = 1)
fit.surv <- survfit(Surv(max_cycle, status) ~ 1)
plot(fit.surv, xlab = "Cycles", ylab = "Estimated Probability for Survival",
main='Kaplan-Meier Estimator')
fit.surv <- survfit(Surv(max_cycle, status) ~ 1)
plot(fit.surv, xlab = "Cycles", ylab = "Estimated Probability for Survival",
main='Kaplan-Meier Survival Curve')
summary(fit.surv, times =150)
print(fit.surv)
### Operational Setting 3
fit.op <- survfit(Surv(max_cycle, status) ~ operational_setting_3)
plot(fit.op, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c (2 ,4), main='Kaplan-Meier Survival Curve Stratified with
operational_setting_3')
legend_labels <- levels(operational_setting_1)
legend("topright", levels(operational_setting_3), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ operational_setting_3)
logrank.test
fit.sm <- survfit(Surv(max_cycle, status) ~ sensor_measurement_16)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c(2,4), main='Kaplan-Meier Survival Curve Stratified with
sensor_measurement_16')
legend("topright", levels(sensor_measurement_16), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ sensor_measurement_16)
logrank.test
coxph(Surv(max_cycle, status) ~ operational_setting_3)
coxph(Surv(max_cycle, status) ~ sensor_measurement_16)
logrank.test <- survdiff(Surv(max_cycle, status) ~ sensor_measurement_16)
logrank.test
fit.sm <- survfit(Surv(max_cycle, status) ~ sensor_measurement_19)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c(2,4), main='Kaplan-Meier Survival Curve
Stratified with sensor_measurement_19')
legend("topright", levels(sensor_measurement_19), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ sensor_measurement_19)
logrank.test
coxph(Surv(max_cycle, status) ~ sensor_measurement_19)
model <- coxph(Surv(max_cycle, status) ~ ., data = turbofan_df)
summary(model)
############### Basic GLMNET
p <- ncol(turbofan_df) - 2
p
data <- as.matrix(turbofan_df[, 3:p])
show_fit=glmnet(data,Surv(max_cycle, status),standardize=TRUE,
lambda=seq(0,0.25,.001),alpha=1,family = "cox")
print(show_fit)
plot(show_fit,label=TRUE)
print(show_fit)
plot(show_fit,label=TRUE)
plot(show_fit,xvar = "lambda",label=TRUE)
################## Partial Devience
surv_model <- cv.glmnet(data,Surv(max_cycle, status), family = "cox",
type.measure = "deviance",alpha=1,nfolds = 10)
plot(surv_model)
print(surv_model)
lambda_opt <- surv_model$lambda.1se
# Fit the model using the optimal lambda value
fit <- glmnet(data,Surv(max_cycle, status), family = "cox",
type.measure = "deviance",alpha=1,lambda = lambda_opt)
coef(fit)
predictions <- predict(fit, newx = data, type = "response")
c_index <- Cindex(predictions,Surv(max_cycle, status))
c_index
################## Cindex
surv_model_C = cv.glmnet(data,Surv(max_cycle, status),
family = "cox", type.measure = "C",
alpha=1,nfolds = 10)
plot(surv_model_C)
print(surv_model_C)
# Fit the model using the optimal lambda value
fit_C <- glmnet(data,Surv(max_cycle, status),
family = "cox",
type.measure = "C",alpha=1,lambda = lambda_opt)
coef(fit_C)
# Make predictions
predictions <- predict(fit_C, newx = data, type = "response")
# Evaluate the model performance using concordance index (c-index)
c_index <- Cindex(predictions,Surv(max_cycle, status))
c_index
lambda_opt <- surv_model_C$lambda.1se
# Fit the model using the optimal lambda value
fit_C <- glmnet(data,Surv(max_cycle, status),
family = "cox",
type.measure = "C",alpha=1,lambda = lambda_opt)
coef(fit_C)
# Make predictions
predictions <- predict(fit_C, newx = data, type = "response")
# Evaluate the model performance using concordance index (c-index)
c_index <- Cindex(predictions,Surv(max_cycle, status))
c_index
lambda_opt <- surv_model_C$lambda.1se
# Fit the model using the optimal lambda value
fit_C <- glmnet(data,Surv(max_cycle, status),
family = "cox",
type.measure = "C",alpha=1,lambda = lambda_opt)
coef(fit_C)
# Make predictions
predictions <- predict(fit_C, newx = data, type = "response")
# Evaluate the model performance using concordance index (c-index)
c_index <- Cindex(predictions,Surv(max_cycle, status))
c_index
library(readr)
library(dplyr)
library(ggplot2)
library(reshape2)
# Define column names
column1 <- c("machine_name", "cycle", "operational_setting_1", "operational_setting_2", "operational_setting_3")
column2 <- paste0("sensor_measurement_", sprintf("%02d", 1:21))
columns <- c(column1, column2)
# Read Data
turbofan_df <- read_delim("data/train_FD002.txt",
delim = " ", col_names = columns, show_col_types = FALSE, trim_ws = TRUE)
# Dropping Empty Columns
turbofan_df <- turbofan_df %>%
select(-X27, -X28)
head(turbofan_df)
turbofan_df <- turbofan_df %>%
group_by(machine_name) %>%
mutate(max_cycle = max(cycle)) %>%
filter(cycle == max_cycle) %>%
ungroup()
head(turbofan_df)
# Create the lollipop plot
ggplot(turbofan_df, aes(x = machine_name, y = cycle)) +
geom_segment(aes(x = machine_name, xend = machine_name, y = 1, yend = cycle), color = 'skyblue') +
geom_point(color = 'blue', size = 1.5) +
geom_point(aes(y = 1), color = 'red', size = 1.5) +
coord_flip() +
labs(title = "Max. Cycle", x = "Machine ID", y = "Cycle") +
theme_minimal()
# Create status column
turbofan_df <- turbofan_df %>%
mutate(status = ifelse(cycle > 200, FALSE, TRUE))
head(turbofan_df)
table(turbofan_df$status)
# Calculate the squared correlation matrix and convert to long format
squared_corr <- cor(turbofan_df)^2
melted_corr <- melt(squared_corr)
# Filter for stronger correlations to reduce clutter
threshold <- 0.5 # Example threshold, adjust as needed
melted_corr_filtered <- subset(melted_corr, value >= threshold & Var1 != Var2)
# Create the heatmap
ggplot(melted_corr_filtered, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
axis.title = element_blank()) +
labs(fill = "Squared\nCorrelation") +
geom_text(aes(label = sprintf("%.2f", value)), size = 3)
# Selected numeric and category columns
selected_columns <- c("sensor_measurement_04", "sensor_measurement_11", "sensor_measurement_14", "operational_setting_3", "sensor_measurement_16", "status", "cycle")
# Assuming 'turbofan_df' is a dataframe and columns are appropriately formatted
cleaned_data <- turbofan_df[selected_columns]
# Calculate the squared correlation matrix and convert to long format
squared_corr <- cor(cleaned_data)^2
melted_corr <- melt(squared_corr)
# Filter for stronger correlations to reduce clutter
threshold <- 0.5 # Example threshold, adjust as needed
melted_corr_filtered <- subset(melted_corr, value >= threshold & Var1 != Var2)
# Create the heatmap
ggplot(melted_corr_filtered, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
axis.title = element_blank()) +
labs(fill = "Squared\nCorrelation") +
geom_text(aes(label = sprintf("%.2f", value)), size = 3)
unique_counts <- sapply(turbofan_df, function(x) length(unique(x)))
cat("Unique values count per column:\n")
for(col in names(unique_counts)) {
cat(col, ":", unique_counts[col], "\n")
}
# Change specified columns to category (factor)
turbofan_df <- turbofan_df %>%
mutate(across(c(operational_setting_3, sensor_measurement_16, sensor_measurement_19), as.factor))
# View information about the dataframe to confirm the changes
glimpse(turbofan_df)
library(survival)
library(dplyr)
library(glmnet)
attach(turbofan_df)
fit.surv <- survfit(Surv(max_cycle, status) ~ 1)
plot(fit.surv, xlab = "Cycles", ylab = "Estimated Probability for Survival",
main='Kaplan-Meier Survival Curve')
summary(fit.surv, times =150)
print(fit.surv)
### Operational Setting 3
fit.op <- survfit(Surv(max_cycle, status) ~ operational_setting_3)
plot(fit.op, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c (2 ,4), main='Kaplan-Meier Survival Curve Stratified with
operational_setting_3')
legend_labels <- levels(operational_setting_1)
legend("topright", levels(operational_setting_3), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ operational_setting_3)
logrank.test
coxph(Surv(max_cycle, status) ~ operational_setting_3)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c(2,4), main='Kaplan-Meier Survival Curve Stratified with
sensor_measurement_16')
fit.sm <- survfit(Surv(max_cycle, status) ~ sensor_measurement_16)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c(2,4), main='Kaplan-Meier Survival Curve Stratified with
sensor_measurement_16')
legend("topright", levels(sensor_measurement_16), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ sensor_measurement_16)
logrank.test
coxph(Surv(max_cycle, status) ~ sensor_measurement_16)
fit.sm <- survfit(Surv(max_cycle, status) ~ sensor_measurement_19)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival",
col = c(2,4), main='Kaplan-Meier Survival Curve
Stratified with sensor_measurement_19')
legend("topright", levels(sensor_measurement_19), col = c(2,4), lty = 1)
logrank.test <- survdiff(Surv(max_cycle, status) ~ sensor_measurement_19)
logrank.test
coxph(Surv(max_cycle, status) ~ sensor_measurement_19)
############### Basic GLMNET
p <- ncol(turbofan_df) - 2
p
data <- as.matrix(turbofan_df[, 3:p])
show_fit=glmnet(data,Surv(max_cycle, status),standardize=TRUE,
lambda=seq(0,0.25,.001),alpha=1,family = "cox")
print(show_fit)
plot(show_fit,label=TRUE)
plot(show_fit,xvar = "lambda",label=TRUE)
################## Partial Devience
surv_model <- cv.glmnet(data,Surv(max_cycle, status), family = "cox",
type.measure = "deviance",alpha=1,nfolds = 10)
plot(surv_model)
print(surv_model)
lambda_opt <- surv_model$lambda.1se
# Fit the model using the optimal lambda value
fit <- glmnet(data,Surv(max_cycle, status), family = "cox",
type.measure = "deviance",alpha=1,lambda = lambda_opt)
coef(fit)
predictions <- predict(fit, newx = data, type = "response")
c_index <- Cindex(predictions,Surv(max_cycle, status))
c_index
################## Cindex
surv_model_C = cv.glmnet(data,Surv(max_cycle, status),
family = "cox", type.measure = "C",
alpha=1,nfolds = 10)
plot(surv_model_C)
print(surv_model_C)
lambda_opt <- surv_model_C$lambda.1se
# Fit the model using the optimal lambda value
fit_C <- glmnet(data,Surv(max_cycle, status),
family = "cox",
type.measure = "C",alpha=1,lambda = lambda_opt)
coef(fit_C)
# Make predictions
predictions <- predict(fit_C, newx = data, type = "response")
# Evaluate the model performance using concordance index (c-index)
c_index <- Cindex(predictions,Surv(max_cycle, status))
c_index
