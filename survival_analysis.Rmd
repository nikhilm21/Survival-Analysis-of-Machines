---
title: "Survival Analysis"
author: "Nikhil, Atharva & Urjit"
date: "2024-04-05"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

This rmd file explains the approach to this problem. It goes over all the techniques utilized in this project and provides a short description for each. The corresponsing project report goes over the results and discusses their implications in greater detail. 

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(survival)
library(glmnet)
```


## Import Data & Preprocessing

```{r}
# Define column names
column1 <- c("machine_name", "cycle", "operational_setting_1", "operational_setting_2", "operational_setting_3")
column2 <- paste0("sensor_measurement_", sprintf("%02d", 1:21))
columns <- c(column1, column2)
```

```{r}
# Read Data
turbofan_df <- read_delim("data/train_FD002.txt",
                          delim = " ", col_names = columns, show_col_types = FALSE, trim_ws = TRUE)

# Dropping Empty Columns
turbofan_df <- turbofan_df %>%
  select(-X27, -X28)

head(turbofan_df)
```

## Data Censoring 

If we examine the data above, we see that we do not have right-censored observations. To obtain such observations, we follow these steps:

1. Select the maximum cycle until each machine breaks down.
2. Assume an endpoint for the observation period.

By doing this, we ensure that our data includes right-censored observations. This is crucial for survival analysis, as it allows us to properly analyze situations where the event of interest (in this case, machine breakdown) has not occurred by the end of the observation period for some subjects (machines). This approach provides a more comprehensive understanding of the lifespan and reliability of the machines by including both those that have failed and those that are still operational by the end of the study.

```{r}
turbofan_df <- turbofan_df %>% 
  group_by(machine_name) %>%
  mutate(max_cycle = max(cycle)) %>%
  filter(cycle == max_cycle) %>%
  ungroup() 

head(turbofan_df)
```

```{r}
# Create the lollipop plot
ggplot(turbofan_df, aes(x = machine_name, y = cycle)) +
  geom_segment(aes(x = machine_name, xend = machine_name, y = 1, yend = cycle), color = 'skyblue') +
  geom_point(color = 'blue', size = 1.5) +
  geom_point(aes(y = 1), color = 'red', size = 1.5) +
  coord_flip() + 
  labs(title = "Max. Cycle", x = "Machine ID", y = "Cycle") +
  theme_minimal()

```

We assume that the final observation time limit is 220 cycles so that when the machine is still active after 220 cycles, the machine will be considered right censored

```{r}
# Create status column
turbofan_df <- turbofan_df %>%
  mutate(status = ifelse(cycle > 200, FALSE, TRUE))

head(turbofan_df)
```

Machine status True indicates that the machine is damaged within the observation time period, while False indicates that the machine has not experienced any damage during the observation time period

```{r}
table(turbofan_df$status)
```

## Exploratory Data Analysis

The next step is to carry out feature selection, namely selecting columns/variables that can be included in the model

#### Correlation Heatmap

We can check the correlation between columns of candidate predictors to see if there is a high correlation between predictors. Variables that have a high correlation with other variables need to be selected only to avoid multicollinearity

```{r}
# Calculate the squared correlation matrix and convert to long format
squared_corr <- cor(turbofan_df)^2
melted_corr <- melt(squared_corr)

# Filter for stronger correlations to reduce clutter
threshold <- 0.5 # Example threshold, adjust as needed
melted_corr_filtered <- subset(melted_corr, value >= threshold & Var1 != Var2)

# Create the heatmap
ggplot(melted_corr_filtered, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "blue", high = "red") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        axis.title = element_blank()) +
  labs(fill = "Squared\nCorrelation") +
  geom_text(aes(label = sprintf("%.2f", value)), size = 3)
```

In the plot above, the correlation between variables looks quite high. In this case we will try to first select the columns sensor_measurement_04, sensor_measurement_08, sensor_measurement_11, sensor_measurement_14 

```{r}
# Selected numeric and category columns
selected_columns <- c("sensor_measurement_04", "sensor_measurement_11", "sensor_measurement_14", "operational_setting_3", "sensor_measurement_16", "status", "cycle")

# Assuming 'turbofan_df' is a dataframe and columns are appropriately formatted
cleaned_data <- turbofan_df[selected_columns]

# Calculate the squared correlation matrix and convert to long format
squared_corr <- cor(cleaned_data)^2
melted_corr <- melt(squared_corr)

# Filter for stronger correlations to reduce clutter
threshold <- 0.5 # Example threshold, adjust as needed
melted_corr_filtered <- subset(melted_corr, value >= threshold & Var1 != Var2)

# Create the heatmap
ggplot(melted_corr_filtered, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "blue", high = "red") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        axis.title = element_blank()) +
  labs(fill = "Squared\nCorrelation") +
  geom_text(aes(label = sprintf("%.2f", value)), size = 3)

```

#### Check for Uniqueness

First we will check for many unique values in each column and then the columns that have few unique values will be replaced with the category data type.

```{r}
unique_counts <- sapply(turbofan_df, function(x) length(unique(x)))

cat("Unique values count per column:\n")
for(col in names(unique_counts)) {
  cat(col, ":", unique_counts[col], "\n")
}
```

The columns `operational_setting_3`, `sensor_measurement_16`, and `sensor_measurement_19` are being converted to factor as there are just 2 unique values in all 3 of those columns.

```{r}
# Change specified columns to category (factor)
turbofan_df <- turbofan_df %>%
  mutate(across(c(operational_setting_3, sensor_measurement_16, sensor_measurement_19), as.factor))

# View information about the dataframe to confirm the changes
glimpse(turbofan_df)
```

## Survival Analysis

```{r}
fit.surv <- survfit(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ 1)
plot(fit.surv, xlab = "Cycles", ylab = "Estimated Probability for Survival", 
     main='Kaplan-Meier Survival Curve')

summary(fit.surv, times =150)

print(fit.surv)
```
The Kaplan-Meier estimator revealed declining survival probabilities for turbofan engines with increasing operational cycles, pinpointing critical periods of heightened failure risk.

#### Analyzing the categorical variables

The categorical variables `operational_setting_3`, `sensor_measurement_16`, and `sensor_measurement_19` will be analyzed using the following methods:

1. Kaplan-Meier Plot
2. Log rank test
3. Cox proportional hazards model stratified on individual variable

##### `operational_setting_3`
```{r}
# Kaplan-Mier Plot
fit.op <- survfit(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$operational_setting_3)
plot(fit.op, xlab = "Cycles", ylab = "Estimated Probability for Survival", 
     col = c (2 ,4), main='Kaplan-Meier Survival Curve Stratified with 
     operational_setting_3')
legend_labels <- levels(turbofan_df$operational_setting_1)

legend("topright", levels(turbofan_df$operational_setting_3), col = c(2,4), lty = 1)   
```

```{r}
#Log rank Test
logrank.test <- survdiff(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$operational_setting_3)

logrank.test
```

The null hypothesis here is that there is no difference in the probability of an event (failure of the turbofan) between operational_setting_3 = 60 and operational_setting_3 = 100. This null hypothesis is rejected after performing the log-rank test because the p-value for the test (0.01) is less than 0.05. Therefore, there is a significant difference in the probability of failure of the turbofan for the two categories in operational_setting_3. This difference in probabilities is quantified by the Cox-proportional hazards model in the next step.

```{r}
# Cox Proportional Hazards Model
coxph(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$operational_setting_3)
```

From the result of the Cox proportional hazards model stratified on operational_setting_3, it can be seen that the value for “exp(coef)” known as the hazard ratio is 0.4764. This indicates that the hazard of failure for engines with operational_setting_3 = 100 is approximately 47.64% lower compared to engines with operational_setting_3 = 60.


In other words, engines operating at setting 100 have a lower risk of failure compared to engines operating at setting 60. This interpretation holds true while considering other factors constant within the model.

#### `sensor_measurement_16`

```{r}
# Kaplan-Mier Survival Curve
fit.sm <- survfit(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$sensor_measurement_16)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival", 
     col = c(2,4), main='Kaplan-Meier Survival Curve Stratified with 
     sensor_measurement_16')

legend("topright", levels(turbofan_df$sensor_measurement_16), col = c(2,4), lty = 1)   
```

```{r}
# Log rank Test
logrank.test <- survdiff(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$sensor_measurement_16)

logrank.test
```

The null hypothesis here is that there is no difference in the probability of an event (failure of the turbofan) between sensor_measurement_16 = 0.02 and sensor_measurement_16 = 0.03. The log-rank test fails to reject this null hypothesis because the p-value for the test (0.08) is greater than 0.05. This non-significant result suggests that there is not enough evidence to conclude that the survival probabilities differ significantly between the categories based on the observed data.

```{r}
# Cox Proportional Hazards Model
coxph(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$sensor_measurement_16)
```

From the result of the Cox proportional hazards model stratified on sensor_measurement_16, it can be seen that the value for “exp(coef)” known as the hazard ratio is 1.3600. This indicates that the hazard of failure for engines with sensor_measurement_16 = 0.03 is approximately 136% higher compared to engines with sensor_measurement_16= 0.02.
In other words, engines operating at a state where sensor_measurement_16 = 0.03 have a higher risk of failure compared to engines operating at sensor_measurement_16 = 0.02. This interpretation holds true while considering other factors constant within the model.

Here, the log-rank test is non-significant, but the hazard ratio is not equal to 1. This implies that although there may not be sufficient statistical evidence to support a significant difference in survival experiences based on the observed data, there still exists a difference in risk between the compared categories according to the hazard ratio estimates. This could be due to factors such as sample size, variability within categories, or the sensitivity of the statistical test used. It's essential to consider both the log-rank test result and the hazard ratio estimate together to understand the overall picture and potential implications for the studied variable's effect on survival outcomes.

##### `sensor_measurement_19`

```{r}
# Kaplan-Mier Plot
fit.sm <- survfit(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$sensor_measurement_19)
plot(fit.sm, xlab = "Cycles", ylab = "Estimated Probability for Survival", 
     col = c(2,4), main='Kaplan-Meier Survival Curve 
     Stratified with sensor_measurement_19')

legend("topright", levels(turbofan_df$sensor_measurement_19), col = c(2,4), lty = 1)   
```

```{r}
#Log rank test
logrank.test <- survdiff(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$sensor_measurement_19)

logrank.test
```

The null hypothesis here is that there is no difference in the probability of an event (failure of the turbofan) between sensor_measurement_19 = 84.93 and sensor_measurement_19 = 100. This null hypothesis is rejected after performing the log-rank test because the p-value for the test (0.01) is less than 0.05. Therefore, there is a significant difference in the probability of failure of the turbofan for the two categories in sensor_measurement_19. This difference in probabilities is quantified by the Cox-proportional hazards model in the next step.

```{r}
#Cox-Proportional test
coxph(Surv(turbofan_df$max_cycle, turbofan_df$status) ~ turbofan_df$sensor_measurement_19)
```

From the result of the Cox proportional hazards model stratified on sensor_measurement_19, it can be seen that the value for “exp(coef)” known as the hazard ratio is 0.4764. This indicates that the hazard of failure for engines with sensor_measurement_19 = 100 is approximately 47.64% lower compared to engines with operational_setting_3 = 84.93.

In other words, engines operating at setting 100 have a lower risk of failure compared to engines operating at setting 84.93. This interpretation holds true while considering other factors constant within the model.

The Cox proportional hazards model revealed that certain operational settings significantly impacted the time to failure of the engines. Notably, higher levels of operational settings 1 and 3 were associated with a reduced survival time, indicating a higher risk of failure. In contrast, operational setting 2 showed a less pronounced effect on engine survival, suggesting its lesser relevance in predicting failure.

## Cox Proportional Hazards model

```{r}
model <- coxph(Surv(max_cycle, status) ~ ., data = turbofan_df)
summary(model)
```

The preliminary Cox Proportional Hazards model using all the variables in the dataset provides an initial estimate of which variables have the most effect on the probability of failure by studying the `exp(coef)` column from the summary of the model.

The values in the `exp(coef)` column demonstrate how the probability of failure is affected by an increase of 1 unit in each of the variables. A positive value indicates an increase in the probability of failure. For the categorical variables, `operational_setting_3`, `sensor_measurement_16`, and `sensor_measurement_19`, the value under `exp(coef)` shows the comparison with the reference category with respect to the effect on the probability of failure.

This is explained in detail in the report.

## GLMNet

```{r}
p <- ncol(turbofan_df) - 2

data <- as.matrix(turbofan_df[, 3:p])
show_fit=glmnet(data,Surv(turbofan_df$max_cycle, turbofan_df$status),standardize=TRUE,
                lambda=seq(0,0.25,.001),alpha=1,family = "cox")
print(show_fit)

plot(show_fit,label=TRUE)
plot(show_fit,xvar = "lambda",label=TRUE) 
```

```{r}
# Partial Deviance
surv_model <- cv.glmnet(data,Surv(turbofan_df$max_cycle, turbofan_df$status), family = "cox", 
                        type.measure = "deviance",alpha=1,nfolds = 10)
plot(surv_model)
print(surv_model)
```
```{r}
lambda_opt <- surv_model$lambda.1se

# Fit the model using the optimal lambda value
fit <- glmnet(data,Surv(turbofan_df$max_cycle, turbofan_df$status), family = "cox", 
              type.measure = "deviance",alpha=1,lambda = lambda_opt)
coef(fit)
```
```{r}
predictions <- predict(fit, newx = data, type = "response")


c_index <- Cindex(predictions,Surv(turbofan_df$max_cycle, turbofan_df$status))
c_index
```

##### C-index

```{r}
surv_model_C = cv.glmnet(data,Surv(turbofan_df$max_cycle, turbofan_df$status), 
                         family = "cox", type.measure = "C", 
                         alpha=1,nfolds = 10)

lambda_opt <- surv_model_C$lambda.1se

plot(surv_model_C)
print(surv_model_C)
```

##### Fit the model using the optimal lambda value

```{r}
fit_C <- glmnet(data,Surv(turbofan_df$max_cycle, turbofan_df$status), 
                family = "cox", 
                type.measure = "C",alpha=1,lambda = lambda_opt)
coef(fit_C)
```

##### Make predictions

```{r}
predictions <- predict(fit_C, newx = data, type = "response")
```
##### Evaluate the model performance using concordance index (c-index)

```{r}
c_index <- Cindex(predictions,Surv(turbofan_df$max_cycle, turbofan_df$status))
c_index
```
